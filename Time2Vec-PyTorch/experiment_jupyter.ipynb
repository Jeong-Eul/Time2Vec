{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DAHS\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from Data import ToyDataset\n",
        "from periodic_activations import SineActivation, CosineActivation\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from Pipeline import AbstractPipelineClass\n",
        "from torch import nn\n",
        "from Model import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = ToyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2048, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2048, 1])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(dataloader))[0].unsqueeze(1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0907, -1.1155,  0.6412, -0.8671,  0.7454, -0.6173, -1.1039, -1.1234,\n",
              "         -1.9529,  1.6660,  0.9530,  1.2307,  0.0391, -0.5589,  2.3281, -0.1776,\n",
              "          0.4811,  0.0039,  0.4520, -0.6064,  0.8018,  1.2675,  1.7066, -0.6072,\n",
              "         -1.2063, -0.7584, -1.4616, -0.0320,  1.1516, -0.5766, -0.2426, -1.5770,\n",
              "         -0.9578, -0.8837,  2.2533, -0.2176, -0.4887, -1.3010,  2.1299,  0.5207,\n",
              "          0.7427]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randn(1, 41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model(\"sin\", 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (l1): SineActivation()\n",
            "  (fc1): Linear(in_features=42, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 8.7182e-03,  1.0105e-01],\n",
              "        [ 4.2275e-01, -2.1112e-01],\n",
              "        [ 5.5826e-01, -2.0625e-01],\n",
              "        ...,\n",
              "        [ 2.7006e+02, -8.6671e+01],\n",
              "        [ 2.6990e+02, -8.6562e+01],\n",
              "        [ 2.7015e+02, -8.7102e+01]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(next(iter(dataloader))[0].unsqueeze(1).float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ToyPipeline(AbstractPipelineClass):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    \n",
        "    def train(self):\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        dataset = ToyDataset()\n",
        "        dataloader = DataLoader(dataset, batch_size=2048, shuffle=False)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "        num_epochs = 100\n",
        "\n",
        "        for ep in range(num_epochs):\n",
        "            for x, y in dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred = self.model(x.unsqueeze(1).float())\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                print(\"epoch: {}, loss:{}\".format(ep, loss.item()))\n",
        "    \n",
        "    def preprocess(self, x):\n",
        "        return x\n",
        "    \n",
        "    def decorate_output(self, x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0, loss:7.503607273101807\n",
            "epoch: 0, loss:21.298128128051758\n",
            "epoch: 0, loss:33.51551818847656\n",
            "epoch: 0, loss:40.66293716430664\n",
            "epoch: 1, loss:5.9918084144592285\n",
            "epoch: 1, loss:16.928598403930664\n",
            "epoch: 1, loss:26.387981414794922\n",
            "epoch: 1, loss:31.57032585144043\n",
            "epoch: 2, loss:4.576334476470947\n",
            "epoch: 2, loss:12.652231216430664\n",
            "epoch: 2, loss:19.281719207763672\n",
            "epoch: 2, loss:22.467695236206055\n",
            "epoch: 3, loss:3.1634035110473633\n",
            "epoch: 3, loss:8.386664390563965\n",
            "epoch: 3, loss:12.207024574279785\n",
            "epoch: 3, loss:13.401391983032227\n",
            "epoch: 4, loss:1.7666834592819214\n",
            "epoch: 4, loss:4.144989013671875\n",
            "epoch: 4, loss:5.171537399291992\n",
            "epoch: 4, loss:4.381922245025635\n",
            "epoch: 5, loss:0.5186298489570618\n",
            "epoch: 5, loss:0.899167537689209\n",
            "epoch: 5, loss:6.2364821434021\n",
            "epoch: 5, loss:5.467772960662842\n",
            "epoch: 6, loss:0.6120070219039917\n",
            "epoch: 6, loss:0.7087919116020203\n",
            "epoch: 6, loss:1.91237473487854\n",
            "epoch: 6, loss:3.2151436805725098\n",
            "epoch: 7, loss:0.695766270160675\n",
            "epoch: 7, loss:1.9719486236572266\n",
            "epoch: 7, loss:3.529047966003418\n",
            "epoch: 7, loss:4.699960231781006\n",
            "epoch: 8, loss:0.8226818442344666\n",
            "epoch: 8, loss:2.184419870376587\n",
            "epoch: 8, loss:3.5295684337615967\n",
            "epoch: 8, loss:4.28879976272583\n",
            "epoch: 9, loss:0.7145262956619263\n",
            "epoch: 9, loss:1.6516509056091309\n",
            "epoch: 9, loss:2.3979616165161133\n",
            "epoch: 9, loss:2.5430829524993896\n",
            "epoch: 10, loss:0.5031353235244751\n",
            "epoch: 10, loss:0.6203341484069824\n",
            "epoch: 10, loss:0.531471848487854\n",
            "epoch: 10, loss:0.8795315027236938\n",
            "epoch: 11, loss:0.7375786900520325\n",
            "epoch: 11, loss:0.753209114074707\n",
            "epoch: 11, loss:0.44949814677238464\n",
            "epoch: 11, loss:0.5811833739280701\n",
            "epoch: 12, loss:0.5261425971984863\n",
            "epoch: 12, loss:0.47652196884155273\n",
            "epoch: 12, loss:0.742280900478363\n",
            "epoch: 12, loss:0.8873530030250549\n",
            "epoch: 13, loss:0.5308437347412109\n",
            "epoch: 13, loss:0.4336356520652771\n",
            "epoch: 13, loss:0.42538002133369446\n",
            "epoch: 13, loss:0.43623796105384827\n",
            "epoch: 14, loss:0.6348565220832825\n",
            "epoch: 14, loss:0.509547770023346\n",
            "epoch: 14, loss:0.4255910813808441\n",
            "epoch: 14, loss:0.52466881275177\n",
            "epoch: 15, loss:0.5641170740127563\n",
            "epoch: 15, loss:0.4349905848503113\n",
            "epoch: 15, loss:0.4460531771183014\n",
            "epoch: 15, loss:0.4700889587402344\n",
            "epoch: 16, loss:0.6089192032814026\n",
            "epoch: 16, loss:0.5540432333946228\n",
            "epoch: 16, loss:0.4450649619102478\n",
            "epoch: 16, loss:0.4556642770767212\n",
            "epoch: 17, loss:0.562224268913269\n",
            "epoch: 17, loss:0.42463746666908264\n",
            "epoch: 17, loss:0.5004907250404358\n",
            "epoch: 17, loss:0.5637843012809753\n",
            "epoch: 18, loss:0.584902822971344\n",
            "epoch: 18, loss:0.5340130925178528\n",
            "epoch: 18, loss:0.45823004841804504\n",
            "epoch: 18, loss:0.4358404278755188\n",
            "epoch: 19, loss:0.5624169707298279\n",
            "epoch: 19, loss:0.42421138286590576\n",
            "epoch: 19, loss:0.5052288174629211\n",
            "epoch: 19, loss:0.5732317566871643\n",
            "epoch: 20, loss:0.5780589580535889\n",
            "epoch: 20, loss:0.5278053879737854\n",
            "epoch: 20, loss:0.4525674879550934\n",
            "epoch: 20, loss:0.43547865748405457\n",
            "epoch: 21, loss:0.5611693263053894\n",
            "epoch: 21, loss:0.4230295717716217\n",
            "epoch: 21, loss:0.49643567204475403\n",
            "epoch: 21, loss:0.5605863928794861\n",
            "epoch: 22, loss:0.5801222920417786\n",
            "epoch: 22, loss:0.5431002974510193\n",
            "epoch: 22, loss:0.45537152886390686\n",
            "epoch: 22, loss:0.4468909800052643\n",
            "epoch: 23, loss:0.5511906147003174\n",
            "epoch: 23, loss:0.421284556388855\n",
            "epoch: 23, loss:0.5090399980545044\n",
            "epoch: 23, loss:0.5617885589599609\n",
            "epoch: 24, loss:0.58223557472229\n",
            "epoch: 24, loss:0.5693365335464478\n",
            "epoch: 24, loss:0.4721802771091461\n",
            "epoch: 24, loss:0.45921120047569275\n",
            "epoch: 25, loss:0.539645254611969\n",
            "epoch: 25, loss:0.42063096165657043\n",
            "epoch: 25, loss:0.5465697646141052\n",
            "epoch: 25, loss:0.5967242121696472\n",
            "epoch: 26, loss:0.5789862275123596\n",
            "epoch: 26, loss:0.5904689431190491\n",
            "epoch: 26, loss:0.49869394302368164\n",
            "epoch: 26, loss:0.469827264547348\n",
            "epoch: 27, loss:0.5280082821846008\n",
            "epoch: 27, loss:0.4280332624912262\n",
            "epoch: 27, loss:0.5944234132766724\n",
            "epoch: 27, loss:0.6502974629402161\n",
            "epoch: 28, loss:0.5683521032333374\n",
            "epoch: 28, loss:0.5836894512176514\n",
            "epoch: 28, loss:0.5180541276931763\n",
            "epoch: 28, loss:0.46643319725990295\n",
            "epoch: 29, loss:0.5248903632164001\n",
            "epoch: 29, loss:0.429965078830719\n",
            "epoch: 29, loss:0.6095069646835327\n",
            "epoch: 29, loss:0.6683863401412964\n",
            "epoch: 30, loss:0.563886284828186\n",
            "epoch: 30, loss:0.5799582004547119\n",
            "epoch: 30, loss:0.5200944542884827\n",
            "epoch: 30, loss:0.46791189908981323\n",
            "epoch: 31, loss:0.5230115056037903\n",
            "epoch: 31, loss:0.4303530156612396\n",
            "epoch: 31, loss:0.6106929779052734\n",
            "epoch: 31, loss:0.6657267808914185\n",
            "epoch: 32, loss:0.5644674301147461\n",
            "epoch: 32, loss:0.5917211771011353\n",
            "epoch: 32, loss:0.5263663530349731\n",
            "epoch: 32, loss:0.4776298999786377\n",
            "epoch: 33, loss:0.5175585150718689\n",
            "epoch: 33, loss:0.43515896797180176\n",
            "epoch: 33, loss:0.6289944052696228\n",
            "epoch: 33, loss:0.6823706030845642\n",
            "epoch: 34, loss:0.5618249773979187\n",
            "epoch: 34, loss:0.5961906313896179\n",
            "epoch: 34, loss:0.5369837880134583\n",
            "epoch: 34, loss:0.48375675082206726\n",
            "epoch: 35, loss:0.5134656429290771\n",
            "epoch: 35, loss:0.4399791955947876\n",
            "epoch: 35, loss:0.6465964317321777\n",
            "epoch: 35, loss:0.7017019987106323\n",
            "epoch: 36, loss:0.5576537251472473\n",
            "epoch: 36, loss:0.5930328369140625\n",
            "epoch: 36, loss:0.543188750743866\n",
            "epoch: 36, loss:0.4842263460159302\n",
            "epoch: 37, loss:0.5116969347000122\n",
            "epoch: 37, loss:0.4413508474826813\n",
            "epoch: 37, loss:0.651398777961731\n",
            "epoch: 37, loss:0.7052547931671143\n",
            "epoch: 38, loss:0.556632936000824\n",
            "epoch: 38, loss:0.5967192053794861\n",
            "epoch: 38, loss:0.5469515323638916\n",
            "epoch: 38, loss:0.48950326442718506\n",
            "epoch: 39, loss:0.5089004635810852\n",
            "epoch: 39, loss:0.4444495737552643\n",
            "epoch: 39, loss:0.660751223564148\n",
            "epoch: 39, loss:0.7139708399772644\n",
            "epoch: 40, loss:0.5547784566879272\n",
            "epoch: 40, loss:0.5990219712257385\n",
            "epoch: 40, loss:0.552684485912323\n",
            "epoch: 40, loss:0.4935379922389984\n",
            "epoch: 41, loss:0.5063071846961975\n",
            "epoch: 41, loss:0.44773027300834656\n",
            "epoch: 41, loss:0.6708093285560608\n",
            "epoch: 41, loss:0.7242280840873718\n",
            "epoch: 42, loss:0.5523340702056885\n",
            "epoch: 42, loss:0.5979719758033752\n",
            "epoch: 42, loss:0.55695641040802\n",
            "epoch: 42, loss:0.49521058797836304\n",
            "epoch: 43, loss:0.5046513080596924\n",
            "epoch: 43, loss:0.44946402311325073\n",
            "epoch: 43, loss:0.6757892966270447\n",
            "epoch: 43, loss:0.7288432121276855\n",
            "epoch: 44, loss:0.5509704351425171\n",
            "epoch: 44, loss:0.5995253324508667\n",
            "epoch: 44, loss:0.5602653622627258\n",
            "epoch: 44, loss:0.49844831228256226\n",
            "epoch: 45, loss:0.5026789307594299\n",
            "epoch: 45, loss:0.4518587291240692\n",
            "epoch: 45, loss:0.6823857426643372\n",
            "epoch: 45, loss:0.7350959181785583\n",
            "epoch: 46, loss:0.5492814779281616\n",
            "epoch: 46, loss:0.5999332666397095\n",
            "epoch: 46, loss:0.5640511512756348\n",
            "epoch: 46, loss:0.500799298286438\n",
            "epoch: 47, loss:0.5009426474571228\n",
            "epoch: 47, loss:0.45401623845100403\n",
            "epoch: 47, loss:0.6883186101913452\n",
            "epoch: 47, loss:0.7411018013954163\n",
            "epoch: 48, loss:0.5475428700447083\n",
            "epoch: 48, loss:0.599566638469696\n",
            "epoch: 48, loss:0.5670367479324341\n",
            "epoch: 48, loss:0.502356231212616\n",
            "epoch: 49, loss:0.4995152950286865\n",
            "epoch: 49, loss:0.4555928409099579\n",
            "epoch: 49, loss:0.6924155950546265\n",
            "epoch: 49, loss:0.7448278665542603\n",
            "epoch: 50, loss:0.5462061762809753\n",
            "epoch: 50, loss:0.6000710129737854\n",
            "epoch: 50, loss:0.5697942972183228\n",
            "epoch: 50, loss:0.5044456720352173\n",
            "epoch: 51, loss:0.497988224029541\n",
            "epoch: 51, loss:0.45745590329170227\n",
            "epoch: 51, loss:0.6972606778144836\n",
            "epoch: 51, loss:0.7496324181556702\n",
            "epoch: 52, loss:0.5446462631225586\n",
            "epoch: 52, loss:0.5997095108032227\n",
            "epoch: 52, loss:0.5724814534187317\n",
            "epoch: 52, loss:0.5057460069656372\n",
            "epoch: 53, loss:0.4966913163661957\n",
            "epoch: 53, loss:0.45891717076301575\n",
            "epoch: 53, loss:0.7009392380714417\n",
            "epoch: 53, loss:0.7531119585037231\n",
            "epoch: 54, loss:0.543282151222229\n",
            "epoch: 54, loss:0.5995283126831055\n",
            "epoch: 54, loss:0.5748298168182373\n",
            "epoch: 54, loss:0.5070787072181702\n",
            "epoch: 55, loss:0.4954306483268738\n",
            "epoch: 55, loss:0.4603426456451416\n",
            "epoch: 55, loss:0.704464852809906\n",
            "epoch: 55, loss:0.7565595507621765\n",
            "epoch: 56, loss:0.5419234037399292\n",
            "epoch: 56, loss:0.5992496013641357\n",
            "epoch: 56, loss:0.577065110206604\n",
            "epoch: 56, loss:0.5081936717033386\n",
            "epoch: 57, loss:0.49424755573272705\n",
            "epoch: 57, loss:0.4616551995277405\n",
            "epoch: 57, loss:0.7076306939125061\n",
            "epoch: 57, loss:0.7595723867416382\n",
            "epoch: 58, loss:0.5406079888343811\n",
            "epoch: 58, loss:0.5988047122955322\n",
            "epoch: 58, loss:0.5791795253753662\n",
            "epoch: 58, loss:0.5091758966445923\n",
            "epoch: 59, loss:0.49312683939933777\n",
            "epoch: 59, loss:0.4628637135028839\n",
            "epoch: 59, loss:0.7104966044425964\n",
            "epoch: 59, loss:0.7624187469482422\n",
            "epoch: 60, loss:0.5393267273902893\n",
            "epoch: 60, loss:0.598328709602356\n",
            "epoch: 60, loss:0.5812370777130127\n",
            "epoch: 60, loss:0.5101469159126282\n",
            "epoch: 61, loss:0.4920486807823181\n",
            "epoch: 61, loss:0.46400728821754456\n",
            "epoch: 61, loss:0.7131984829902649\n",
            "epoch: 61, loss:0.7651044726371765\n",
            "epoch: 62, loss:0.5380542278289795\n",
            "epoch: 62, loss:0.597719669342041\n",
            "epoch: 62, loss:0.583078145980835\n",
            "epoch: 62, loss:0.510831892490387\n",
            "epoch: 63, loss:0.4910595715045929\n",
            "epoch: 63, loss:0.4649956226348877\n",
            "epoch: 63, loss:0.715395987033844\n",
            "epoch: 63, loss:0.7672374248504639\n",
            "epoch: 64, loss:0.536882221698761\n",
            "epoch: 64, loss:0.5971634984016418\n",
            "epoch: 64, loss:0.584922194480896\n",
            "epoch: 64, loss:0.5114849209785461\n",
            "epoch: 65, loss:0.4900624752044678\n",
            "epoch: 65, loss:0.46603742241859436\n",
            "epoch: 65, loss:0.7177976965904236\n",
            "epoch: 65, loss:0.7696254849433899\n",
            "epoch: 66, loss:0.5356288552284241\n",
            "epoch: 66, loss:0.5963133573532104\n",
            "epoch: 66, loss:0.5865188241004944\n",
            "epoch: 66, loss:0.5117458701133728\n",
            "epoch: 67, loss:0.4891890585422516\n",
            "epoch: 67, loss:0.46678096055984497\n",
            "epoch: 67, loss:0.7193734645843506\n",
            "epoch: 67, loss:0.7710697054862976\n",
            "epoch: 68, loss:0.5345525145530701\n",
            "epoch: 68, loss:0.5959309339523315\n",
            "epoch: 68, loss:0.5881139039993286\n",
            "epoch: 68, loss:0.5123634338378906\n",
            "epoch: 69, loss:0.4882417619228363\n",
            "epoch: 69, loss:0.4677513539791107\n",
            "epoch: 69, loss:0.7215372920036316\n",
            "epoch: 69, loss:0.7732582688331604\n",
            "epoch: 70, loss:0.5333204865455627\n",
            "epoch: 70, loss:0.5949467420578003\n",
            "epoch: 70, loss:0.5896267294883728\n",
            "epoch: 70, loss:0.5124009251594543\n",
            "epoch: 71, loss:0.4874354302883148\n",
            "epoch: 71, loss:0.46836936473846436\n",
            "epoch: 71, loss:0.7228124141693115\n",
            "epoch: 71, loss:0.774398148059845\n",
            "epoch: 72, loss:0.5322813987731934\n",
            "epoch: 72, loss:0.5944899320602417\n",
            "epoch: 72, loss:0.5910467505455017\n",
            "epoch: 72, loss:0.5128235816955566\n",
            "epoch: 73, loss:0.48656269907951355\n",
            "epoch: 73, loss:0.4691965579986572\n",
            "epoch: 73, loss:0.7245977520942688\n",
            "epoch: 73, loss:0.7762858867645264\n",
            "epoch: 74, loss:0.5311161279678345\n",
            "epoch: 74, loss:0.5935506224632263\n",
            "epoch: 74, loss:0.5924475193023682\n",
            "epoch: 74, loss:0.5128734707832336\n",
            "epoch: 75, loss:0.4858003258705139\n",
            "epoch: 75, loss:0.46977075934410095\n",
            "epoch: 75, loss:0.7256305813789368\n",
            "epoch: 75, loss:0.7773892283439636\n",
            "epoch: 76, loss:0.530121922492981\n",
            "epoch: 76, loss:0.5928475856781006\n",
            "epoch: 76, loss:0.5938670635223389\n",
            "epoch: 76, loss:0.5131115913391113\n",
            "epoch: 77, loss:0.4849865436553955\n",
            "epoch: 77, loss:0.4705137610435486\n",
            "epoch: 77, loss:0.7272366285324097\n",
            "epoch: 77, loss:0.7789693474769592\n",
            "epoch: 78, loss:0.5289729237556458\n",
            "epoch: 78, loss:0.5916926264762878\n",
            "epoch: 78, loss:0.5951955318450928\n",
            "epoch: 78, loss:0.5130472779273987\n",
            "epoch: 79, loss:0.484270304441452\n",
            "epoch: 79, loss:0.47095274925231934\n",
            "epoch: 79, loss:0.7279553413391113\n",
            "epoch: 79, loss:0.7794692516326904\n",
            "epoch: 80, loss:0.5280293822288513\n",
            "epoch: 80, loss:0.5913054347038269\n",
            "epoch: 80, loss:0.596365213394165\n",
            "epoch: 80, loss:0.513232409954071\n",
            "epoch: 81, loss:0.4834725260734558\n",
            "epoch: 81, loss:0.471671462059021\n",
            "epoch: 81, loss:0.729478120803833\n",
            "epoch: 81, loss:0.7811554670333862\n",
            "epoch: 82, loss:0.5268866419792175\n",
            "epoch: 82, loss:0.5900650024414062\n",
            "epoch: 82, loss:0.5976197719573975\n",
            "epoch: 82, loss:0.5128272771835327\n",
            "epoch: 83, loss:0.4828137159347534\n",
            "epoch: 83, loss:0.4720001518726349\n",
            "epoch: 83, loss:0.7300084829330444\n",
            "epoch: 83, loss:0.7816280126571655\n",
            "epoch: 84, loss:0.5259641408920288\n",
            "epoch: 84, loss:0.5894977450370789\n",
            "epoch: 84, loss:0.5987175703048706\n",
            "epoch: 84, loss:0.5129386782646179\n",
            "epoch: 85, loss:0.4820777475833893\n",
            "epoch: 85, loss:0.47258296608924866\n",
            "epoch: 85, loss:0.7311208248138428\n",
            "epoch: 85, loss:0.7827466130256653\n",
            "epoch: 86, loss:0.5249230861663818\n",
            "epoch: 86, loss:0.5885069370269775\n",
            "epoch: 86, loss:0.5998770594596863\n",
            "epoch: 86, loss:0.5126697421073914\n",
            "epoch: 87, loss:0.481417179107666\n",
            "epoch: 87, loss:0.4729803502559662\n",
            "epoch: 87, loss:0.7318115234375\n",
            "epoch: 87, loss:0.7834036946296692\n",
            "epoch: 88, loss:0.5239551067352295\n",
            "epoch: 88, loss:0.587670624256134\n",
            "epoch: 88, loss:0.6009690761566162\n",
            "epoch: 88, loss:0.5126065015792847\n",
            "epoch: 89, loss:0.4807407557964325\n",
            "epoch: 89, loss:0.47340837121009827\n",
            "epoch: 89, loss:0.7325568199157715\n",
            "epoch: 89, loss:0.7842041850090027\n",
            "epoch: 90, loss:0.5229822397232056\n",
            "epoch: 90, loss:0.5868539214134216\n",
            "epoch: 90, loss:0.6019781827926636\n",
            "epoch: 90, loss:0.5123715996742249\n",
            "epoch: 91, loss:0.48008301854133606\n",
            "epoch: 91, loss:0.4738018810749054\n",
            "epoch: 91, loss:0.733170211315155\n",
            "epoch: 91, loss:0.7848272919654846\n",
            "epoch: 92, loss:0.5220115184783936\n",
            "epoch: 92, loss:0.586037814617157\n",
            "epoch: 92, loss:0.6030021905899048\n",
            "epoch: 92, loss:0.5120958685874939\n",
            "epoch: 93, loss:0.4794439375400543\n",
            "epoch: 93, loss:0.4741501212120056\n",
            "epoch: 93, loss:0.7338036894798279\n",
            "epoch: 93, loss:0.7855008840560913\n",
            "epoch: 94, loss:0.5210548639297485\n",
            "epoch: 94, loss:0.5851099491119385\n",
            "epoch: 94, loss:0.6040278077125549\n",
            "epoch: 94, loss:0.5118414759635925\n",
            "epoch: 95, loss:0.4788196384906769\n",
            "epoch: 95, loss:0.47449609637260437\n",
            "epoch: 95, loss:0.7343248724937439\n",
            "epoch: 95, loss:0.785929799079895\n",
            "epoch: 96, loss:0.5201394557952881\n",
            "epoch: 96, loss:0.5842357873916626\n",
            "epoch: 96, loss:0.6050208806991577\n",
            "epoch: 96, loss:0.5115386843681335\n",
            "epoch: 97, loss:0.47820281982421875\n",
            "epoch: 97, loss:0.47484371066093445\n",
            "epoch: 97, loss:0.7349023818969727\n",
            "epoch: 97, loss:0.7865332365036011\n",
            "epoch: 98, loss:0.5191968679428101\n",
            "epoch: 98, loss:0.5832560658454895\n",
            "epoch: 98, loss:0.6059315800666809\n",
            "epoch: 98, loss:0.5111464858055115\n",
            "epoch: 99, loss:0.4776180684566498\n",
            "epoch: 99, loss:0.47508424520492554\n",
            "epoch: 99, loss:0.7351595163345337\n",
            "epoch: 99, loss:0.7868356704711914\n"
          ]
        }
      ],
      "source": [
        "pipe = ToyPipeline(Model(\"sin\", 42))\n",
        "pipe.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
